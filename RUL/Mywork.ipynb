{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "from mindspore import ops as ops\n",
    "from mindspore import Tensor\n",
    "from mindspore import numpy as np\n",
    "from mindspore.ops import operations as P\n",
    "import math\n",
    "class PositionalEncoding(nn.Cell):\n",
    "\n",
    "    def __init__(self,d_model, dropout=0.1, max_len=500) -> None:\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(keep_prob=1-dropout)\n",
    "        # https://www.mindspore.cn/docs/zh-CN/r2.0.0-alpha/note/api_mapping/pytorch_diff/mindspore.nn.Dropout.html?highlight=Dropout\n",
    "        position = np.arange(max_len).reshape(max_len,1)\n",
    "        div_term = ops.exp(np.arange(0, d_model, 2)*(-math.log(10000.0) / d_model))\n",
    "        pe = np.zeros((max_len,d_model))\n",
    "        pe[:, 0::2] = ops.sin(position * div_term)\n",
    "        pe[:, 1::2] = ops.cos(position * div_term)\n",
    "        self.pe=pe\n",
    "\n",
    "    def construct(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, seq_len, feature_num]\n",
    "        \"\"\"\n",
    "        # pe with shape: \n",
    "        x = ops.add(x, self.pe[:x.shape[1]].unsqueeze(0))\n",
    "        # 所有的操作都必须ops来搞\n",
    "        return self.dropout(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_len = 24 \n",
    "d_model = 24\n",
    "\n",
    "position = np.arange(max_len).reshape(max_len,1)\n",
    "div_term = ops.exp(np.arange(0, d_model, 2)*(-math.log(10000.0) / d_model))\n",
    "pe = np.zeros((max_len,d_model))\n",
    "pe[:, 0::2] = ops.sin(position * div_term)\n",
    "pe[:, 1::2] = ops.cos(position * div_term)\n",
    "add_x = pe[:24].unsqueeze(0)\n",
    "x = Tensor(np.ones((2,24,24)))\n",
    "res_x = pe_test(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Discriminator(nn.Cell): #D_y\n",
    "    def __init__(self, auto_prefix=True, flags=None, in_features=24):\n",
    "        super().__init__(auto_prefix, flags)\n",
    "        self.in_features = in_features\n",
    "        self.li = nn.SequentialCell(\n",
    "            nn.Dense(in_features,512),\n",
    "            # to config the detail\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dense(512,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.alpha = 1 \n",
    "    \n",
    "    def construct(self, x):\n",
    "        # 由于实现了自定义的算子，因此需要进行迁移\n",
    "        # https://zhuanlan.zhihu.com/p/548702030 -> 直接在forward处进行修改\n",
    "        # 前向传播的过程中使用了梯度翻转层的\n",
    "        # 确定需求所在：https://www.mindspore.cn/tutorials/experts/zh-CN/r1.10/network/custom_cell_reverse.html\n",
    "        # jump forward\n",
    "        if x.shape[0] == 1:\n",
    "            pad = np.zeros((1,self.in_features))\n",
    "            # cuda?\n",
    "            x = ops.concat((x,pad))\n",
    "            # diff in concat https://www.mindspore.cn/docs/zh-CN/r1.9/note/api_mapping/pytorch_diff/Concat.html\n",
    "            y = self.li(x)[0].unsqueeze(0)\n",
    "            return y\n",
    "        return self.li(x)\n",
    "\n",
    "class backboneDiscriminator(nn.Cell): #D_f\n",
    "    def __init__(self, seq_len, d=24):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len \n",
    "        self.li1 = nn.Dense(seq_len, 512)\n",
    "        self.li2 = nn.SequentialCell(\n",
    "            nn.Dense(seq_len,512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dense(512,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def construct(self,x):\n",
    "        # jump forward\n",
    "        out1 = self.li1(x).squeeze(2)\n",
    "        if x.shape[0] ==1:\n",
    "            pad = np.zeros((1,self.seq_len))\n",
    "            out1 = ops.concat((out1,pad))\n",
    "            out2 = self.li2(out1)[0].unsqueeze(0)\n",
    "            return out2\n",
    "        out2 = self.li2(out1)\n",
    "        return out2\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "d_model = 20\n",
    "pe = np.zeros((max_len,d_model))\n",
    "position = np.arange(max_len).reshape(max_len,1)\n",
    "div_term = ops.exp(np.arange(start=0, stop=d_model, step=2)*(-math.log(10000.0) / d_model))\n",
    "pe[:, 0::2] = ops.sin(position * div_term)\n",
    "pe[:, 1::2] = ops.cos(position * div_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[1, 100, 20], dtype=Float32, value=\n",
       "[[[ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00 ...  1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
       "  [ 8.41471016e-01,  5.40302277e-01,  3.87674242e-01 ...  9.99999821e-01,  2.51188554e-04,  9.99999940e-01],\n",
       "  [ 9.09297466e-01, -4.16146815e-01,  7.14713454e-01 ...  9.99999225e-01,  5.02377108e-04,  9.99999881e-01],\n",
       "  ...\n",
       "  [ 3.79607737e-01, -9.25147533e-01,  7.93952167e-01 ...  9.98127699e-01,  2.43628789e-02,  9.99703169e-01],\n",
       "  [-5.73381841e-01, -8.19288254e-01,  9.67561126e-01 ...  9.98088896e-01,  2.46139914e-02,  9.99697030e-01],\n",
       "  [-9.99206841e-01,  3.98208797e-02,  9.89835501e-01 ...  9.98049736e-01,  2.48651039e-02,  9.99690831e-01]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 500\n",
    "position = torch.arange(max_len).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import Tensor\n",
    "import mindspore.numpy as np\n",
    "position = np.arange(max_len).reshape(max_len,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_356/2868711915.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmindspore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdiv_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from mindspore import ops as ops\n",
    "import math\n",
    "div_term = ops.Exp(np.arange(0, d_model, 2)*(-math.log(10000.0) / d_model))\n",
    "\n",
    "\n",
    "pe = np.zeros(max_len,d_model)\n",
    "\n",
    "pe[:, 0::2] = ops.sin(position * div_term)\n",
    "pe[:, 1::2] = ops.cos(position * div_term)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import mindspore.numpy as np\n",
    "print(np.zeros((2,2)))\n",
    "\n",
    "\n",
    "a = np.zeros((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "import mindspore.nn.transformer as trans\n",
    "from mindspore.common import initializer\n",
    "class mymodel(nn.Cell):\n",
    "\n",
    "    def __init__(self, d_model = 24, dropout=0.1, nhead=8, nlayers=2, max_len=500):\n",
    "        super().__init__()\n",
    "        self.max_len = max_len\n",
    "        self.pos_encoder = PositionalEncoding(d_model,nlayers)\n",
    "        self.transformer_encoder = trans.TransformerEncoder(num_layers=nlayers,d_model=d_model,num_heads=nhead,ffn_hidden_size=512,dropout=0.1,post_layernorm_residual=True)\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(1-dropout)\n",
    "        self.decoder = nn.Dense(d_model, 1 ,weight_init = initializer.Uniform(scale=0.1) )\n",
    "        # bias default is zeros\n",
    "        \n",
    "    def construct(self, src, key_msk, attn_msk=None):\n",
    "        src = self.pos_encoder(src)\n",
    "        output1 = self.transformer_encoder(src, attn_msk, key_msk)\n",
    "        output2 = self.decoder(output1)\n",
    "        return output1, output2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:11<00:00,  6.03it/s]\n",
      "100%|██████████| 182/182 [00:28<00:00,  6.36it/s]\n",
      "100%|██████████| 78/78 [00:12<00:00,  6.21it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "For 'Dropout', the type of 'keep_prob' should be 'float', but got type 'int'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_341715/2178911676.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# prepare model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmymodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mD1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mD2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackboneDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Domain-Adaptive-Remaining-Useful-Life-Prediction-with-Transformer/RUL/mymodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, d_model, dropout, nhead, nlayers, max_len)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPositionalEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransformerEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnlayers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnhead\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mffn_hidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpost_layernorm_residual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Domain-Adaptive-Remaining-Useful-Life-Prediction-with-Transformer/RUL/mymodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, d_model, dropout, max_len)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;31m# https://www.mindspore.cn/docs/zh-CN/r2.0.0-alpha/note/api_mapping/pytorch_diff/mindspore.nn.Dropout.html?highlight=Dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mposition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/nn/layer/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, keep_prob, dtype)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;34m\"\"\"Initialize Dropout.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mValidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_value_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'keep_prob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeep_prob\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkeep_prob\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             raise ValueError(f\"For '{self.cls_name}', the 'keep_prob' must be a number in range (0, 1], \"\n",
      "\u001b[0;32m/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/_checkparam.py\u001b[0m in \u001b[0;36mcheck_value_type\u001b[0;34m(arg_name, arg_value, valid_types, prim_name)\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[0marg_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m             \u001b[0mraise_error_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/_checkparam.py\u001b[0m in \u001b[0;36mraise_error_msg\u001b[0;34m()\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0mnum_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0mmsg_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"For '{prim_name}', the\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprim_name\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"The\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m             raise TypeError(f'{msg_prefix} type of \\'{arg_name}\\' should be {\"one of \" if num_types > 1 else \"\"}'\n\u001b[0m\u001b[1;32m    644\u001b[0m                             \u001b[0;34mf'\\'{type_names if num_types > 1 else type_names[0]}\\', '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m                             f'but got type \\'{type(arg_value).__name__}\\'.')\n",
      "\u001b[0;31mTypeError\u001b[0m: For 'Dropout', the type of 'keep_prob' should be 'float', but got type 'int'."
     ]
    }
   ],
   "source": [
    "from mydataset import TRANSFORMER_DATA_MINDS,TRANSFORMER_ALL_DATA_MINDS\n",
    "from mymodel import mymodel, Discriminator, backboneDiscriminator\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy\n",
    "import os \n",
    "import mindspore.dataset as ds\n",
    "target= 'FD002'\n",
    "source = 'FD003'\n",
    "epoches = 240\n",
    "os.chdir('/Domain-Adaptive-Remaining-Useful-Life-Prediction-with-Transformer/')\n",
    "batch_size = 1000\n",
    "seq_len = 70\n",
    "source_list = numpy.loadtxt(\"save/\"+source+\"/train\"+source+\".txt\", dtype=str).tolist()\n",
    "target_list = numpy.loadtxt(\"save/\"+target+\"/train\"+target+\".txt\", dtype=str).tolist()\n",
    "valid_list = numpy.loadtxt(\"save/\"+target+\"/test\"+target+\".txt\", dtype=str).tolist()\n",
    "a_list = numpy.loadtxt(\"save/\"+target+\"/valid\"+target+\".txt\", dtype=str).tolist()\n",
    "target_test_names = valid_list + a_list\n",
    "minl = min(len(source_list), len(target_list))\n",
    "s_data = TRANSFORMER_ALL_DATA_MINDS(source_list, seq_len)\n",
    "t_data = TRANSFORMER_ALL_DATA_MINDS(target_list, seq_len)\n",
    "t_data_test = TRANSFORMER_ALL_DATA_MINDS(target_test_names, seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "For 'Dropout', the type of 'keep_prob' should be 'float', but got type 'int'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_341715/3509228994.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# prepare model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmymodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mD1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mD2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackboneDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Domain-Adaptive-Remaining-Useful-Life-Prediction-with-Transformer/RUL/mymodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, d_model, dropout, nhead, nlayers, max_len)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPositionalEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransformerEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnlayers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnhead\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mffn_hidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpost_layernorm_residual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Domain-Adaptive-Remaining-Useful-Life-Prediction-with-Transformer/RUL/mymodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, d_model, dropout, max_len)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;31m# https://www.mindspore.cn/docs/zh-CN/r2.0.0-alpha/note/api_mapping/pytorch_diff/mindspore.nn.Dropout.html?highlight=Dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mposition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/nn/layer/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, keep_prob, dtype)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;34m\"\"\"Initialize Dropout.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mValidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_value_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'keep_prob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeep_prob\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkeep_prob\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             raise ValueError(f\"For '{self.cls_name}', the 'keep_prob' must be a number in range (0, 1], \"\n",
      "\u001b[0;32m/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/_checkparam.py\u001b[0m in \u001b[0;36mcheck_value_type\u001b[0;34m(arg_name, arg_value, valid_types, prim_name)\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[0marg_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m             \u001b[0mraise_error_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/_checkparam.py\u001b[0m in \u001b[0;36mraise_error_msg\u001b[0;34m()\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0mnum_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0mmsg_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"For '{prim_name}', the\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprim_name\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"The\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m             raise TypeError(f'{msg_prefix} type of \\'{arg_name}\\' should be {\"one of \" if num_types > 1 else \"\"}'\n\u001b[0m\u001b[1;32m    644\u001b[0m                             \u001b[0;34mf'\\'{type_names if num_types > 1 else type_names[0]}\\', '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m                             f'but got type \\'{type(arg_value).__name__}\\'.')\n",
      "\u001b[0;31mTypeError\u001b[0m: For 'Dropout', the type of 'keep_prob' should be 'float', but got type 'int'."
     ]
    }
   ],
   "source": [
    "\n",
    "# prepare model\n",
    "net = mymodel(max_len=seq_len) \n",
    "D1 = Discriminator(seq_len)\n",
    "D2 = backboneDiscriminator(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seq_len' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1083403/1387034508.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmindspore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmindspore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLossMonitor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmymodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'seq_len' is not defined"
     ]
    }
   ],
   "source": [
    "from mydataset import TRANSFORMER_DATA_MINDS,TRANSFORMER_ALL_DATA_MINDS\n",
    "from mymodel import mymodel, Discriminator, backboneDiscriminator\n",
    "from myloss import advLoss\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy\n",
    "import os \n",
    "import mindspore.dataset as ds\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "from mindspore import Model,ParameterTuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "from mindspore import Model\n",
    "from mindspore import dataset as ds\n",
    "from mindspore.nn import LossBase\n",
    "from mindspore.common.initializer import Normal\n",
    "from mindspore.train.callback import LossMonitor\n",
    "net = mymodel(max_len=seq_len,batch_size=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
